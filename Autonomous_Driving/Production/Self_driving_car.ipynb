{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XHFnthirwlfn"
   },
   "outputs": [],
   "source": [
    "# Credits: https://github.com/SullyChen/Autopilot-TensorFlow\n",
    "# Research paper: End to End Learning for Self-Driving Cars by Nvidia. [https://arxiv.org/pdf/1604.07316.pdf]\n",
    "\n",
    "# NVidia dataset: 72 hrs of video => 72*60*60*30 = 7,776,000 images\n",
    "# Nvidia blog: https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "# Our Dataset: https://github.com/SullyChen/Autopilot-TensorFlow [https://drive.google.com/file/d/0B-KJCaaF7elleG1RbzVPZWV4Tlk/view]\n",
    "# Size: 25 minutes = 25*60*30 = 45,000 images ~ 2.3 GB\n",
    "\n",
    "\n",
    "# If you want to try on a slightly large dataset: 70 minutes of data ~ 223GB\n",
    "# Refer: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5\n",
    "# Format: Image, latitude, longitude, gear, brake, throttle, steering angles and speed\n",
    "\n",
    "\n",
    "\n",
    "# Additional Installations:\n",
    "# pip3 install h5py\n",
    "\n",
    "\n",
    "# AWS: https://aws.amazon.com/blogs/machine-learning/get-started-with-deep-learning-using-the-aws-deep-learning-ami/\n",
    "\n",
    "# Youtube:https://www.youtube.com/watch?v=qhUvQiKec2U\n",
    "# Further reading and extensions: https://medium.com/udacity/teaching-a-machine-to-steer-a-car-d73217f2492c\n",
    "# More data: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_ys = ys[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_ys = ys[-int(len(xs) * 0.2):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[180, 162, 166],\n",
       "        [176, 172, 173],\n",
       "        [176, 176, 171],\n",
       "        ...,\n",
       "        [ 90,  88, 113],\n",
       "        [106,  93,  99],\n",
       "        [101, 103,  81]],\n",
       "\n",
       "       [[191, 188, 192],\n",
       "        [186, 193, 204],\n",
       "        [187, 196, 200],\n",
       "        ...,\n",
       "        [ 84,  82,  97],\n",
       "        [ 86,  88,  79],\n",
       "        [ 86, 101,  74]],\n",
       "\n",
       "       [[208, 201, 223],\n",
       "        [199, 212, 230],\n",
       "        [201, 212, 226],\n",
       "        ...,\n",
       "        [128, 124, 115],\n",
       "        [128, 126, 117],\n",
       "        [132, 126, 119]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 54,  43,  55],\n",
       "        [ 59,  43,  56],\n",
       "        [ 55,  41,  53],\n",
       "        ...,\n",
       "        [ 23,  24,  25],\n",
       "        [ 24,  25,  27],\n",
       "        [ 25,  26,  29]],\n",
       "\n",
       "       [[ 56,  36,  58],\n",
       "        [ 53,  35,  63],\n",
       "        [ 51,  39,  54],\n",
       "        ...,\n",
       "        [ 23,  25,  22],\n",
       "        [ 23,  26,  23],\n",
       "        [ 24,  27,  25]],\n",
       "\n",
       "       [[ 68,  37,  44],\n",
       "        [ 53,  41,  49],\n",
       "        [ 49,  49,  37],\n",
       "        ...,\n",
       "        [ 28,  25,  26],\n",
       "        [ 26,  23,  25],\n",
       "        [ 24,  22,  24]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.misc.imresize(scipy.misc.imread(train_xs[0])[-150:], [66, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installed\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.atan(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vgcc6iQobKHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing data.txt\n"
     ]
    }
   ],
   "source": [
    "# read images and steering angles from driving_dataset folder\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "\n",
    "DATA_FOLDER = './driving_dataset/' # change this to your folder\n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt')\n",
    "\n",
    "\n",
    "split =0.8\n",
    "X = []\n",
    "y = []\n",
    "with open(TRAIN_FILE) as fp:\n",
    "    for line in islice(fp,45567):\n",
    "        path, angle = line.strip().split()\n",
    "        full_path = os.path.join(DATA_FOLDER, path)\n",
    "        X.append(full_path)\n",
    "        \n",
    "        # converting angle from degrees to radians\n",
    "        y.append(float(angle) * pi / 180 )\n",
    "\n",
    "\n",
    "y = np.array(y)\n",
    "print(\"Completed processing data.txt\")\n",
    "\n",
    "split_index = int(len(y)*0.8)\n",
    "\n",
    "train_y = y[:split_index]\n",
    "test_y = y[split_index:]\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive analysis\n",
      "Measures of Central Tendency\n",
      "Mean = 0.0345988749016117\n",
      "Median = 0.01064650843716541\n",
      "Measures of Dispersion\n",
      "Minimum = -2.6680848275237317\n",
      "Maximum = 8.757713120657145\n",
      "Range = 11.425797948180877\n",
      "Variance = 0.31619413226973125\n",
      "Standard Deviation = 0.5623114192951547\n",
      "&****************&\n",
      "Descriptive analysis\n",
      "Measures of Central Tendency\n",
      "Mean = 0.013891375693268053\n",
      "Median = 0.045727626402251434\n",
      "Measures of Dispersion\n",
      "Minimum = -2.791305072714531\n",
      "Maximum = 1.281246203889037\n",
      "Range = 4.072551276603568\n",
      "Variance = 0.1906980731712859\n",
      "Standard Deviation = 0.43668990504852057\n",
      "&****************&\n",
      "                  0\n",
      "count  36324.000000\n",
      "mean       0.034599\n",
      "std        0.562319\n",
      "min       -2.668085\n",
      "25%       -0.123220\n",
      "50%        0.010647\n",
      "75%        0.135438\n",
      "max        8.757713\n",
      "&****************&\n",
      "                 0\n",
      "count  9082.000000\n",
      "mean      0.013891\n",
      "std       0.436714\n",
      "min      -2.791305\n",
      "25%      -0.015882\n",
      "50%       0.045728\n",
      "75%       0.170693\n",
      "max       1.281246\n"
     ]
    }
   ],
   "source": [
    "arr=train_y\n",
    "# measures of central tendency\n",
    "def numpy_describe(arr):\n",
    "    mean = np.mean(arr)\n",
    "    median = np.median(arr)\n",
    "\n",
    "    # measures of dispersion\n",
    "    min = np.amin(arr)\n",
    "    max = np.amax(arr)\n",
    "    range = np.ptp(arr)\n",
    "    variance = np.var(arr)\n",
    "    sd = np.std(arr)\n",
    "\n",
    "    print(\"Descriptive analysis\")\n",
    "    #print(\"Array =\", arr)\n",
    "    print(\"Measures of Central Tendency\")\n",
    "    print(\"Mean =\", mean)\n",
    "    print(\"Median =\", median)\n",
    "    print(\"Measures of Dispersion\")\n",
    "    print(\"Minimum =\", min)\n",
    "    print(\"Maximum =\", max)\n",
    "    print(\"Range =\", range)\n",
    "    print(\"Variance =\", variance)\n",
    "    print(\"Standard Deviation =\", sd)\n",
    "numpy_describe(train_y)\n",
    "print(\"&****************&\")\n",
    "numpy_describe(test_y)\n",
    "\n",
    "\n",
    "def pandas_desc(arr):\n",
    "    df=pd.DataFrame(arr)\n",
    "    print(df.describe())\n",
    "\n",
    "print(\"&****************&\")\n",
    "pandas_desc(train_y)\n",
    "print(\"&****************&\")\n",
    "pandas_desc(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy;\n",
    "\n",
    "# PDF of train and test 'y' values. \n",
    "import matplotlib.pyplot as plt \n",
    "plt.hist(train_y, bins=50, density=True, color='green', histtype ='step')\n",
    "plt.hist(test_y, bins=50, density=True, color='red', histtype ='step')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_MSE(MEAN):0.191127\n",
      "Test_MSE(ZERO):0.190891\n"
     ]
    }
   ],
   "source": [
    "#Model 0: Base line Model: y_test_pred = mean(y_train_i) \n",
    "train_mean_y = np.mean(train_y)\n",
    "\n",
    "print('Test_MSE(MEAN):%f' % np.mean(np.square(test_y-train_mean_y)) )\n",
    "\n",
    "print('Test_MSE(ZERO):%f' % np.mean(np.square(test_y-0.0)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nTensor name \"Variable_20\" not found in checkpoint files save/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"D:\\installed\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\installed\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-034a423fdeae>\", line 8, in <module>\n    saver = tf.train.Saver()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nTensor name \"Variable_20\" not found in checkpoint files save/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Tensor name \"Variable_20\" not found in checkpoint files save/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1725\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1726\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Tensor name \"Variable_20\" not found in checkpoint files save/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"D:\\installed\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\installed\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-034a423fdeae>\", line 8, in <module>\n    saver = tf.train.Saver()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Tensor name \"Variable_20\" not found in checkpoint files save/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1736\u001b[0m         object_graph_string = reader.get_tensor(\n\u001b[1;32m-> 1737\u001b[1;33m             checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[0;32m   1738\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m    350\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[1;32m--> 351\u001b[1;33m                                           status)\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-034a423fdeae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"save/model.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'steering_wheel_image.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \u001b[1;31m# a helpful message (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1743\u001b[1;33m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[0;32m   1744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       \u001b[1;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nTensor name \"Variable_20\" not found in checkpoint files save/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"D:\\installed\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\installed\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\installed\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-034a423fdeae>\", line 8, in <module>\n    saver = tf.train.Saver()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 397, in _AddRestoreOps\n    restore_sequentially)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 829, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nTensor name \"Variable_20\" not found in checkpoint files save/model.ckpt\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\t [[Node: save/RestoreV2/_7 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import model\n",
    "import cv2\n",
    "from subprocess import call\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save/model.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    ret, frame = cap.read()\n",
    "    image = scipy.misc.imresize(frame, [66, 200]) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.keep_prob: 1.0})[0][0] * 180 / scipy.pi\n",
    "    call(\"clear\")\n",
    "    print(\"Predicted steering angle: \" + str(degrees) + \" degrees\")\n",
    "    cv2.imshow('frame', frame)\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.atan(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Self_driving_car.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
